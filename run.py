#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
STSb Auto-Tune Agent v6 ä¸»å…¥å£è„šæœ¬ / Main Entry Point

âš¡ ä¸€é”®è¿è¡Œè‡ªåŠ¨è°ƒå‚ Agent

ç”¨æ³• / Usage:
    python run.py

ğŸ’¡ è¦æ”¹é…ç½®ï¼Œç¼–è¾‘ config.py
ğŸ’¡ To modify config, edit config.py
"""

import json
import os
import shutil
from copy import deepcopy
from typing import Dict, Any, List, Optional

# å¯¼å…¥æ ¸å¿ƒæ¨¡å— / Import core modules
from config import DEFAULT_CONFIG, TUNABLE_KEYS, AGENT_SETTINGS
from core.training import (
    make_default_config,
    export_config_for_agent,
)
from agents.gpt_agent import (
    ask_gpt_for_initial_plan,
    ask_gpt_for_new_config,
    ask_gpt_for_overall_summary,
)
from utils.report_generator import generate_run_report


def apply_new_config(base_config: Dict[str, Any], new_config: Dict[str, Any]) -> Dict[str, Any]:
    """
    æŠŠ GPT è¿”å›çš„ new_config åº”ç”¨åˆ°å½“å‰ configï¼ˆåªè¦†ç›–å·²æœ‰é”®ï¼‰
    Apply new config from GPT (only override existing keys)
    """
    cfg = deepcopy(base_config)
    for k, v in new_config.items():
        if k in cfg:
            cfg[k] = v
    return cfg


def run_agent() -> None:
    """
    ä¸»å‡½æ•°ï¼šåè°ƒæ•´ä¸ªè‡ªåŠ¨è°ƒå‚æµç¨‹
    Main orchestration function
    """
    print("=" * 70)
    print("ğŸš€ STSb Auto-Tune Agent v6ï¼ˆæ§åˆ¶å˜é‡ + å•å˜é‡é¡ºåºè°ƒå‚ï¼‰")
    print("=" * 70)
    print()

    # åˆå§‹åŒ–é…ç½® / Initialize configuration
    from core.training import train_one_round

    current_config = make_default_config()

    print("ğŸ‘‰ é»˜è®¤åˆå§‹è¶…å‚ï¼ˆä»…æ˜¾ç¤ºå¯è°ƒå‚éƒ¨åˆ†ï¼‰:")
    print(json.dumps(export_config_for_agent(current_config), ensure_ascii=False, indent=2))
    print()

    # å…¨å±€æœ€ä½³ç»Ÿè®¡ / Global best tracking
    best_score: float = -1e9
    best_round: Optional[int] = None
    best_config: Optional[Dict[str, Any]] = None
    best_output_dir: Optional[str] = None

    # å†å²è®°å½• / History tracking
    history_for_agent: List[Dict[str, Any]] = []

    # ========= ç¬¬ 0 æ­¥ï¼šè®© GPT é€‰å‡º base_config + priority_keys =========
    base_cfg: Dict[str, Any] = {}
    valid_priority_keys: List[str] = []

    try:
        print("\n===== æ­¥éª¤ 0 / Step 0: è°ƒç”¨ GPT ç”Ÿæˆ base_config + priority_keys =====")
        init_plan = ask_gpt_for_initial_plan(
            export_config_for_agent(current_config),
            model=AGENT_SETTINGS.GPT_MODEL,
        )
        base_cfg = init_plan.get("base_config") or {}
        priority_keys = init_plan.get("priority_keys") or []
        comment = init_plan.get("comment", "")

        # è¿‡æ»¤ä¼˜å…ˆçº§ key / Filter priority keys
        valid_priority_keys: List[str] = []
        for k in priority_keys:
            if isinstance(k, str) and k in TUNABLE_KEYS and k not in valid_priority_keys:
                valid_priority_keys.append(k)

        if not valid_priority_keys:
            # å…œåº•ç­–ç•¥ / Fallback
            valid_priority_keys = TUNABLE_KEYS[:AGENT_SETTINGS.MAX_PRIORITY_PARAMS]

        print("\n===== GPT å¯¹åˆå§‹ç­–ç•¥çš„è¯´æ˜ / GPT Initial Strategy =====")
        print(comment)
        print("\nğŸ‘‰ å»ºè®®ä¼˜å…ˆè°ƒå‚é¡ºåº / Priority keys:", valid_priority_keys)

        # åº”ç”¨ base_config / Apply base config
        if isinstance(base_cfg, dict):
            filtered_base_cfg = {k: v for k, v in base_cfg.items() if k in current_config}
            if filtered_base_cfg:
                current_config = apply_new_config(current_config, filtered_base_cfg)

        print("\nâœ… åº”ç”¨ base_config åçš„åˆå§‹è¶…å‚ / Initial config after applying base_config:")
        print(json.dumps(export_config_for_agent(current_config), ensure_ascii=False, indent=2))

    except Exception as e:
        print(f"\nâš ï¸  åˆå§‹è®¡åˆ’è°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥ / Initial plan failed, using default strategy")
        print(f"   é”™è¯¯ / Error: {repr(e)}")
        valid_priority_keys = TUNABLE_KEYS[:AGENT_SETTINGS.MAX_PRIORITY_PARAMS]

    # æœ€å¤šåªè°ƒå‰ N ä¸ªå‚æ•° / Max parameters to tune
    MAX_PARAMS = min(AGENT_SETTINGS.MAX_PRIORITY_PARAMS, len(valid_priority_keys))
    ROUNDS_PER_PARAM = AGENT_SETTINGS.ROUNDS_PER_PARAM
    global_round_id: int = 0

    # ========= ä¾æ¬¡å¯¹ priority_keys åšæ§åˆ¶å˜é‡å•å˜é‡è°ƒå‚ =========
    # ========= Loop over each priority key for single-variable tuning =========
    for param_index in range(MAX_PARAMS):
        key = valid_priority_keys[param_index]
        print("\n" + "=" * 70)
        print(f"=== å‚æ•° {param_index + 1}/{MAX_PARAMS} / Parameter {param_index + 1}/{MAX_PARAMS}: {key} ===")
        print("=" * 70)

        param_best_score: float = -1e9
        param_best_round: Optional[int] = None
        param_best_value = current_config.get(key, None)

        for inner_round in range(1, ROUNDS_PER_PARAM + 1):
            global_round_id += 1
            print("\n" + "-" * 70)
            print(f"è½®æ¬¡ / Round {global_round_id} - {key} ç¬¬ {inner_round}/{ROUNDS_PER_PARAM} è½®")
            print("-" * 70)
            print("å½“å‰å…³é”®è¶…å‚ / Current config:")
            print(json.dumps(export_config_for_agent(current_config), ensure_ascii=False, indent=2))

            # è®­ç»ƒ / Training
            training_summary, full_metrics = train_one_round(current_config, round_id=global_round_id)
            main_score = float(training_summary["main_score"])
            print(f"\nğŸ”¹ æœ¬è½®åˆ†æ•° / Score: {main_score:.4f}")

            # è®°å½•å†å² / Record history
            history_item: Dict[str, Any] = {
                "round_id": global_round_id,
                "tuned_key": key,
                "inner_round_index": inner_round,
                "config_for_agent": export_config_for_agent(current_config),
                "main_score": main_score,
                "metrics": full_metrics,
            }
            history_for_agent.append(history_item)

            # æ›´æ–°è¯¥å‚æ•°å†…éƒ¨çš„æœ€ä½³è®°å½• / Update parameter's best score
            cur_value = current_config.get(key, None)
            if main_score > param_best_score:
                param_best_score = main_score
                param_best_round = global_round_id
                param_best_value = cur_value

            # æ›´æ–°å…¨å±€æœ€ä½³è®°å½• / Update global best score
            if main_score > best_score:
                best_score = main_score
                best_round = global_round_id
                best_config = export_config_for_agent(current_config)
                best_output_dir = training_summary.get("output_dir", None)
                print(f"ğŸ† æ–°çš„å…¨å±€æœ€ä¼˜ / New global best! Round #{best_round}, score={best_score:.4f}")

            # è°ƒç”¨ GPT è·å–å»ºè®® / Call GPT for suggestions
            try:
                suggestion = ask_gpt_for_new_config(
                    export_config_for_agent(current_config),
                    training_summary,
                    model=AGENT_SETTINGS.GPT_MODEL,
                    history=history_for_agent,
                    primary_key=key,
                )
            except Exception as e:
                print(f"\nâš ï¸  GPT è°ƒç”¨å¤±è´¥ï¼Œæœ¬å‚æ•°è°ƒå‚æå‰ç»“æŸ / GPT call failed, ending this parameter's tuning")
                print(f"   é”™è¯¯ / Error: {repr(e)}")
                break

            print("\n===== GPT çš„è¯„ä»· / GPT Comment =====")
            print(suggestion["comment"])

            new_cfg_from_agent = suggestion.get("new_config") or {}

            # åº”ç”¨å»ºè®® / Apply suggestion
            if key in new_cfg_from_agent:
                new_val = new_cfg_from_agent[key]
                print(f"\nğŸ‘‰ GPT å»ºè®®æ–°å€¼ / Suggested new value: {key} = {new_val!r}")
                current_config = apply_new_config(current_config, {key: new_val})
            else:
                print(f"\nâš ï¸  GPT æœªè¿”å› {key}ï¼Œä¿æŒå½“å‰å€¼ / GPT didn't suggest {key}, keeping current value")

            # ç”¨æˆ·ç¡®è®¤ / User confirmation
            if AGENT_SETTINGS.INTERACTIVE_MODE and inner_round < ROUNDS_PER_PARAM:
                ans = input(f"\nç»§ç»­ä¸‹ä¸€è½®å—ï¼Ÿ/ Continue next round? (y/n): ").strip().lower()
                if ans not in ("y", "yes", "1", "æ˜¯", "å¥½"):
                    print("ğŸ›‘ ç”¨æˆ·é€‰æ‹©ç»“æŸè¯¥å‚æ•°çš„è°ƒå‚ / User chose to end this parameter's tuning")
                    break

        # ä¸€ä¸ªå‚æ•°çš„è°ƒå‚ç»“æŸ / Parameter tuning complete
        if param_best_value is not None:
            print(f"\nâœ… å‚æ•° {key} è°ƒå‚å®Œæˆ / Parameter {key} tuning complete")
            print(f"   è¯¥å‚æ•°æœ€ä½³: è½®æ¬¡ #{param_best_round}, åˆ†æ•° {param_best_score:.4f}, {key}={param_best_value!r}")
            current_config = apply_new_config(current_config, {key: param_best_value})
            print(f"   å·²å›ºå®š {key} çš„æœ€ä½³å€¼ï¼Œè½¬å‘ä¸‹ä¸€å‚æ•°")
        else:
            print(f"\nâš ï¸  å‚æ•° {key} æ— æœ‰æ•ˆè®°å½• / No valid records for {key}, keeping current value")

        # é˜¶æ®µæ€§æ€»ç»“ / Progress report
        print("\nğŸ“Œ å½“å‰å…¨å±€æœ€ä½³ / Current Global Best:")
        print(f"   è½®æ¬¡ #{best_round}, åˆ†æ•° {best_score:.4f}")
        if best_config is not None:
            print("   å¯¹åº”é…ç½® / Corresponding config:")
            print(json.dumps(best_config, ensure_ascii=False, indent=2))

        # è¯¢é—®æ˜¯å¦ç»§ç»­ä¸‹ä¸€å‚æ•° / Ask user about next parameter
        if AGENT_SETTINGS.INTERACTIVE_MODE and param_index < MAX_PARAMS - 1:
            next_key = valid_priority_keys[param_index + 1]
            ans = input(f"\nç»§ç»­è°ƒä¸‹ä¸€ä¸ªå‚æ•°ï¼ˆ{next_key}ï¼‰å—ï¼Ÿ/ Continue with {next_key}? (y/n): ").strip().lower()
            if ans not in ("y", "yes", "1", "æ˜¯", "å¥½"):
                print("ğŸ›‘ ç”¨æˆ·é€‰æ‹©ç»“æŸè°ƒå‚ / User chose to end tuning")
                break

    # ========= å…¨éƒ¨è°ƒå‚æµç¨‹ç»“æŸ =========
    # ========= Post-processing =========
    print("\n" + "=" * 70)
    print("âœ¨ è°ƒå‚å®Œæˆ / Auto-Tuning Complete")
    print("=" * 70)
    print(f"\nğŸ“Š æœ€ç»ˆç»“æœ / Final Results:")
    print(f"   æœ€ä½³è½®æ¬¡ / Best round: {best_round}")
    print(f"   æœ€ä½³åˆ†æ•° / Best score: {best_score:.4f}")
    if best_config is not None:
        print("   æœ€ä½³é…ç½® / Best config:")
        for k, v in sorted(best_config.items()):
            print(f"      {k}: {v}")

    # å¤åˆ¶æœ€ä½³æ¨¡å‹ / Copy best model
    if best_output_dir is not None:
        try:
            parent_dir = os.path.dirname(best_output_dir.rstrip("/\\"))
            best_overall_dir = os.path.join(parent_dir, "best_overall_model")
            print(f"\nğŸ“¦ å¤åˆ¶æœ€ä½³æ¨¡å‹ / Copying best model...")
            print(f"   ä» / From: {best_output_dir}")
            print(f"   åˆ° / To: {best_overall_dir}")
            shutil.copytree(best_output_dir, best_overall_dir, dirs_exist_ok=True)
            print("âœ… æ¨¡å‹å¤åˆ¶å®Œæˆ / Best model copied")
        except Exception as e:
            print(f"\nâš ï¸  å¤åˆ¶æœ€ä½³æ¨¡å‹å¤±è´¥ï¼ˆä¸å½±å“ç»“æœï¼‰/ Copy failed (doesn't affect results): {repr(e)}")

    # ç”ŸæˆæŠ¥å‘Š / Generate report
    try:
        report_path = generate_run_report(
            history_for_agent,
            best_round,
            float(best_score),
            best_config,
            valid_priority_keys,
            base_cfg,
        )
    except Exception as e:
        print(f"\nâš ï¸  ç”ŸæˆæŠ¥å‘Šå¤±è´¥ï¼ˆä¸å½±å“ç»“æœï¼‰/ Report generation failed: {repr(e)}")

    # ç”Ÿæˆæ•´ä½“æ€»ç»“ / Generate overall summary
    try:
        print("\n" + "=" * 70)
        print("ğŸ“ GPT æ•´ä½“æ€»ç»“ / Overall Summary from GPT")
        print("=" * 70)
        overall_comment = ask_gpt_for_overall_summary(
            history_for_agent,
            best_round if best_round is not None else -1,
            float(best_score),
            best_config if best_config is not None else {},
            model=AGENT_SETTINGS.GPT_MODEL,
        )
        print(overall_comment)
    except Exception as e:
        print(f"\nâš ï¸  ç”Ÿæˆæ€»ç»“å¤±è´¥ï¼ˆä¸å½±å“ç»“æœï¼‰/ Summary generation failed: {repr(e)}")

    print("\n" + "=" * 70)
    print("âœ¨ æ‰€æœ‰æµç¨‹å·²å®Œæˆ / All done!")
    print("=" * 70)


if __name__ == "__main__":
    try:
        run_agent()
    except KeyboardInterrupt:
        print("\n\nâ›” ç”¨æˆ·ä¸­æ–­ / User interrupted")
    except Exception as e:
        print(f"\n\nâŒ ç¨‹åºå‡ºé”™ / Fatal error: {repr(e)}")
        import traceback
        traceback.print_exc()
