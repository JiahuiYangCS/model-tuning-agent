"""
Report Generator module / æŠ¥å‘Šç”Ÿæˆæ¨¡å—

ç”Ÿæˆè®­ç»ƒè¿è¡Œçš„ä¸­è‹±åŒè¯­ Markdown æŠ¥å‘Š
"""

import os
import json
from datetime import datetime
from typing import Dict, Any, List, Optional


def generate_run_report(
    history: List[Dict[str, Any]],
    best_round: Optional[int],
    best_score: float,
    best_config: Optional[Dict[str, Any]],
    priority_keys: List[str],
    base_cfg: Dict[str, Any],
) -> str:
    """
    ç”Ÿæˆä¸€ä»½ç®€å•çš„ä¸­è‹±åŒè¯­æŠ¥å‘Šï¼Œæ€»ç»“ agent åœ¨æœ¬æ¬¡è¿è¡Œä¸­æ¯ä¸€æ­¥åšäº†ä»€ä¹ˆï¼Œå¹¶æŠŠæŠ¥å‘Šå†™åˆ° `docs/reports/`
    
    å‚æ•° / Args:
        history: è®­ç»ƒå†å²è®°å½•åˆ—è¡¨
        best_round: æœ€ä½³è½®æ¬¡ç¼–å·
        best_score: æœ€ä½³åˆ†æ•°
        best_config: æœ€ä½³é…ç½®
        priority_keys: ä¼˜å…ˆè°ƒå‚çš„é”®åˆ—è¡¨
        base_cfg: åˆå§‹ base_config
    
    è¿”å› / Returns:
        æŠ¥å‘Šæ–‡ä»¶çš„ç»å¯¹è·¯å¾„
    """
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_dir = os.path.join(os.getcwd(), "docs", "reports")
    os.makedirs(report_dir, exist_ok=True)
    filename = f"agent_run_report_{ts}.md"
    report_path = os.path.join(report_dir, filename)

    lines: List[str] = []
    lines.append(f"# Agent è¿è¡ŒæŠ¥å‘Š / Agent Run Report ({ts})\n")
    lines.append("## æ¦‚è¦ / Summary\n")
    lines.append(f"- ä¼˜å…ˆè°ƒå‚åˆ—è¡¨ / Priority keys: {priority_keys}\n")
    lines.append(f"- åº”ç”¨çš„ base_config / Base config applied: {json.dumps(base_cfg, ensure_ascii=False)}\n")
    lines.append(f"- å†å²æœ€ä½³è½®æ¬¡ / Best round: {best_round}, æœ€ä½³åˆ†æ•° / Best score: {best_score:.4f}\n")

    lines.append("## é€è½®è®°å½• / Per-round log (CN/EN explanations)\n")
    if not history:
        lines.append("æ— å†å²è®°å½• / No history recorded.\n")
    else:
        for h in history:
            rid = h.get("round_id")
            key = h.get("tuned_key")
            inner = h.get("inner_round_index")
            cfg = h.get("config_for_agent")
            score = h.get("main_score")

            lines.append(f"### è½®æ¬¡ / Round {rid} â€” è°ƒå‚é”® / Tuned key: {key} (inner {inner})\n")
            lines.append(f"- æœ¬è½®ä½¿ç”¨çš„é…ç½® / Config used: {json.dumps(cfg, ensure_ascii=False)}\n")
            lines.append(f"- æœ¬è½®ä¸»è¯„ä¼°åˆ†æ•° / Main score: {score}\n")
            lines.append(f"- ç®€è¦è¯´æ˜ï¼ˆä¸­æ–‡ï¼‰/ Brief (CN): æœ¬è½®å¯¹ `{key}` è¿›è¡Œäº†å•å˜é‡è°ƒå‚ï¼Œè®°å½•äº†å½“å‰å–å€¼ä¸è¯„ä¼°åˆ†æ•°ï¼Œç”¨äºæ¯”è¾ƒæ˜¯å¦ä¼˜äºä¹‹å‰çš„å–å€¼ã€‚\n")
            lines.append(f"- Brief (EN): This round tuned the single key `{key}` and recorded its value and evaluation score to compare with previous values.\n")
            lines.append("\n")

    lines.append("## ç»“è®ºä¸ä¸‹ä¸€æ­¥å»ºè®® / Conclusions & Next Steps\n")
    lines.append("- ç»“è®ºï¼ˆä¸­æ–‡ï¼‰/ Conclusion (CN): è¯·æŸ¥çœ‹ above çš„æ¯è½®è¯„åˆ†ï¼Œé€‰æ‹©è¯„åˆ†æœ€é«˜çš„é…ç½®ä½œä¸ºæœ€ç»ˆä½¿ç”¨æˆ–è¿›ä¸€æ­¥éªŒè¯ã€‚\n")
    lines.append("- Conclusion (EN): Inspect per-round scores above and pick the best-scoring configuration for final use or further validation.\n")
    lines.append("- å»ºè®® / Suggestion: å¯å°† best_config ç”¨äºåç»­æ›´é•¿è®­ç»ƒï¼Œæˆ–æ‰©å¤§æ•°æ®/ä¿®æ”¹åº•æ¨¡ä»¥è¿›ä¸€æ­¥æå‡ã€‚\n")

    # å†™æ–‡ä»¶
    with open(report_path, "w", encoding="utf-8") as f:
        f.write("\n".join(lines))

    # æ‰“å°æŠ¥å‘Šè·¯å¾„å¹¶è¿”å›
    print(f"\nğŸ“„ è¿è¡ŒæŠ¥å‘Šå·²ç”Ÿæˆ / Report generated: {report_path}")
    return report_path
